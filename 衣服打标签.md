# 服装打标签 解决方案

数据集 Caterory and Attribute Prediction Benchmark

共计289222张图片，数据集中包含的信息：

> #### _Img/Images.zip_：包含着图片数据
>
> 1. 图片格式为jpg
> 2. 将图片缩放到最长边为300pixels，比例不变

> #### Anno/list_bbox.txt: 记录着每一个boundding box的位置
>
> 1. 除了第一第二行外，都是以 图片路径 图片bounding box的位置
> 2. boundingbox 的位置其实是以四元组表示，左上角x,y和右下角x,y

> #### Anno/list_landmark.txt 图片分类标签与标定位置
>
> 1. <image name> <clothes type> <variation type> [<landmark visibility 1> <landmark location x_1> <landmark location y_1>, ... <landmark visibility 8> <landmark location x_8> <landmark location y_8>]
>
>    ​	<图片名字>
>
>    ​	<服装类别>：包括上衣、下装、全身三种，分别为1,2,3
>
>    ​	<变量类型>：表示图片的姿势，分别由正常姿态，中等姿态，大姿态，这是怎么分的呢？
>
>    ​	<>

## 1. 多任务学习

服装的类别是互斥的

服装的特性是可以重合的

服装的位置的提取，与landmark的识别，是否互斥？

有必要在landmark之前就先检测服装的位置吗？

如果图片的大小以服装为主，那么这个就是useless，如果图片中大多为背景的话，就会是有必要的，同时可能一定程度上提高了运行的速度。

两者组合在一起，在最后的卷积层之后，分为三个branch

但是要想能够正确的预测这个服装分类的话，首先需要正确的切分出这个图片，并确定类别。



//两级级联，级联强监督。之后，再做一个多任务的学习。

//第一级的级联其实做的就是关于服装的位置的预测，最后的conv_layer的输出featrue //map作为输入，输入到下一级级联。后面跟着两层的fc产生出boundingbox的位置。

运用technique: 

1. Hard-Aware，对于失败的样本，收集并存储，再次训练，提高惩罚比例。
2. 正负例学习

//第二级级联就是基于刚才的featuremap

还是直接Faster-RCNN 吧



联合多个损失函数分步骤进行权重调整

faster-RCNN 最后一层分为三个branch，

首先是上/下/全身服装/背景或其他的识别

对于是服装的进行

## 2. 特性的检测方式 

借助