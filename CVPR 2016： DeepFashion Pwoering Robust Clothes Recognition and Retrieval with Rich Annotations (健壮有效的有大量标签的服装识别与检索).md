# CVPR 2016： DeepFashion: Pwoering Robust Clothes Recognition and Retrieval with Rich Annotations (健壮有效的有大量标签的服装识别与检索)

> Abstract：
>
> 1. 提出一个大规模的数据集，超过80000张图片，被大量标记的。服装类型的模型评测数据集。而且图片拍摄于于多个场景（店拍、街拍、消费者自拍）/多种姿势
> 2. 提出一个FashionNet的模型，通过预测服装特性和标志来学习衣服的特征。

## 1. Background

### 1.1 服装识别算法要解决的三个问题：

1. 服装在款式、纹理和裁剪上有很多的变型，让已有的系统难以解决预测问题。
2. 服装的很容易就变型或者叠合在一起。
3. 服装图片在不同的环境下会有很多大的变化，比如线上的图片和自拍相比。

### 1.2 数据集

1. 别人的数据集各种不足：
   1. 仅仅含有后者的某一些部分，而本数据集deepFashion都包含了（服装的语义特征、服装的位置、不同场景下的服装相关性）
   2. 给更多标志/特征部分的位置
2. 于是提出了更大数据集，更多的标注。。。。还小心的确定了为三大任务提供评判数据集和验证协议
3. DeepFashion数据集描述
   1. 两倍于前人数据集大小，shop/consumer images
   2. 丰富标记的服装类项，50类，1000个描述特性和标志
   3. 包含着30000张多姿势/多源（shop/consumer）的图片对。
4. 数据集的产生方式
   1. 来源于网上的电商网站，和客户评价的网站收集到的关于391482个服装类别的1320078张图片。
   2. 谷歌搜索的服装图片，12684次不同的搜索，总共1273150张图片。
   3. 合在一起清洗。通过利用AlexNet的fc-7的输出比较来分辨出相近/一模一样的复制的图片，删除复制后得出的图片经过人工的标记来删除低分辨率/图片质量或者根本不是服装的图片。
   4. 最终得出800K张图片
5. 图片标注

> 1. 大量的特性：重要的类别信息来认出或者表现楚大量的服装项。
> 2. Landmarks：利用服装特定位置的标记来处理解决服装变型或者时姿势的多样。
> 3. Consumer-to-shop pairs ：用于克服不同场景下的图片的识别能力问题

​	1. _生成类别与特性列表_：源于用户搜索（这绝对是跟电商网站合作了，拿到了资料）将搜索的adj+n中将名词提取，然后将adj合并一起，提取前1000个高频的作为特性。特性被氛围5个类别，分别为：

​		1）纹理	2）面料	3）形状 4）部分（？上下装/全身装等等） 5）款式

​	2. _类别与特性标记_：类别集大小适中（50类），类别标记是定义上是互斥的。每一张图片最多接收一个类别标记。对于1000个特性，特性多而且，每张图片可以有多个特性，不可控制。因此对于手工标记的特性标记进行重新排序。特别的，对于每一张图片，我们对比特性列表和对应的手工标记（数据搜集过程中获得的）将与特性列表匹配的认为是“fired”，枚举每组前10个特性

​	3. _Landmark 标记_